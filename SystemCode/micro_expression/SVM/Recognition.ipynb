{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8946a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import utils as np_utils\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,CSVLogger\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2409fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ae035d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e847e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Ying\\\\Downloads\\\\LBP_TOP'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_dir=os.getcwd()\n",
    "orig_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8242ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Full HOF Data\n",
    "features_data_hof_full=[]\n",
    "features_label_hof_full=[]\n",
    "\n",
    "path=\"C:/Users/Ying/Downloads/LBP_TOP/HOF_cropped_classified\"\n",
    "folders=os.listdir(path)\n",
    "t_count=0\n",
    "for f in folders:\n",
    "    count=1\n",
    "    folder_path=os.path.join(path, f)\n",
    "    files=os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        file_path=os.path.join(folder_path,file)\n",
    "        features=os.listdir(file_path)\n",
    "        for feature in features:\n",
    "            feature_path=os.path.join(file_path,feature)\n",
    "            histogram=np.load(feature_path)\n",
    "            histogram = np.mean(histogram, axis=0)\n",
    "            features_data_hof_full.append(histogram)\n",
    "            features_label_hof_full.append(f)\n",
    "            count=count+1\n",
    "            t_count=t_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ede93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = features_data_hof_full\n",
    "length = max(map(len, x))\n",
    "features_data_hof_full = np.array([np.concatenate((xi,[0]*(length-len(xi)))) for xi in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b42c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 14256)\n"
     ]
    }
   ],
   "source": [
    "# features_data_hof_full=np.reshape(features_data_hof_full,(10,15)).T\n",
    "# print(features_data_hof_full.shape)\n",
    "print(features_data_hof_full.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4550ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = features_data_hof_full\n",
    "# y = features_label_hof_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99c7e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Full LBP Data\n",
    "features_data_l=[]\n",
    "features_label_l=[]\n",
    "\n",
    "path=\"C:/Users/Ying/Downloads/LBP_TOP/LBP_TOP_cropped_classified\"\n",
    "folders=os.listdir(path)\n",
    "t_count=0\n",
    "for f in folders:\n",
    "    count=1\n",
    "    folder_path=os.path.join(path, f)\n",
    "    files=os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        file_path=os.path.join(folder_path,file)\n",
    "        features=os.listdir(file_path)\n",
    "        for feature in features:\n",
    "            feature_path=os.path.join(file_path,feature)\n",
    "            histogram=np.load(feature_path)\n",
    "            histogram = np.mean(histogram, axis=0)\n",
    "            features_data_l.append(histogram)\n",
    "            features_label_l.append(f)\n",
    "            count=count+1\n",
    "            t_count=t_count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e753be29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 768)\n"
     ]
    }
   ],
   "source": [
    "# Process to correct format for DNN\n",
    "features_data_l=np.concatenate(features_data_l, axis=1).T\n",
    "\n",
    "print(features_data_l.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b782d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = features_data_l\n",
    "# y = features_label_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85319635",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((features_data_hof_full,features_data_l),axis=1)\n",
    "y = features_label_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dbe01ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 15024)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29aac33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoder of labels\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(y)\n",
    "dummy_y = np_utils.to_categorical(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3152222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location='C:/Users/Ying/Downloads/LBP_TOP/Run_time_data'\n",
    "modelname= 'RB_FF_NN13'\n",
    "savelocation=os.path.join(save_location, modelname)\n",
    "filepath=savelocation + \".hdf5\"\n",
    "csv_logger=CSVLogger(savelocation +'.csv')\n",
    "#callbacks_list  = [checkpoint,csv_logger,LRScheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c607d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               7692800   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 8,482,820\n",
      "Trainable params: 8,482,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='sigmoid', input_shape=(X.shape[1],)))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(512, activation='sigmoid'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eeaa423",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks=[csv_logger, ModelCheckpoint(filepath,monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "952bbcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "60/60 [==============================] - 4s 57ms/step - loss: 1.6103 - accuracy: 0.3277 - val_loss: 1.5028 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 1.4398 - accuracy: 0.3697 - val_loss: 0.5706 - val_accuracy: 1.0000\n",
      "Epoch 3/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3648 - accuracy: 0.3950 - val_loss: 1.3516 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3651 - accuracy: 0.3277 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
      "Epoch 5/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4035 - accuracy: 0.3782 - val_loss: 0.8665 - val_accuracy: 1.0000\n",
      "Epoch 6/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4229 - accuracy: 0.3613 - val_loss: 1.0278 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4269 - accuracy: 0.3277 - val_loss: 0.8208 - val_accuracy: 1.0000\n",
      "Epoch 8/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.4333 - accuracy: 0.3613 - val_loss: 0.9329 - val_accuracy: 1.0000\n",
      "Epoch 9/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4063 - accuracy: 0.3193 - val_loss: 0.5727 - val_accuracy: 1.0000\n",
      "Epoch 10/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4165 - accuracy: 0.3782 - val_loss: 1.5408 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4358 - accuracy: 0.3613 - val_loss: 0.8900 - val_accuracy: 1.0000\n",
      "Epoch 12/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3688 - accuracy: 0.3866 - val_loss: 0.3919 - val_accuracy: 1.0000\n",
      "Epoch 13/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4439 - accuracy: 0.3782 - val_loss: 0.9292 - val_accuracy: 1.0000\n",
      "Epoch 14/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3932 - accuracy: 0.3529 - val_loss: 0.7179 - val_accuracy: 1.0000\n",
      "Epoch 15/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3946 - accuracy: 0.3697 - val_loss: 1.1229 - val_accuracy: 1.0000\n",
      "Epoch 16/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4215 - accuracy: 0.3697 - val_loss: 1.2335 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4045 - accuracy: 0.3697 - val_loss: 0.9810 - val_accuracy: 1.0000\n",
      "Epoch 18/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4181 - accuracy: 0.3613 - val_loss: 0.9177 - val_accuracy: 1.0000\n",
      "Epoch 19/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3884 - accuracy: 0.3782 - val_loss: 1.1612 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4202 - accuracy: 0.3361 - val_loss: 1.4437 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3998 - accuracy: 0.3613 - val_loss: 1.3375 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4054 - accuracy: 0.3529 - val_loss: 0.5242 - val_accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3963 - accuracy: 0.4118 - val_loss: 1.0328 - val_accuracy: 1.0000\n",
      "Epoch 24/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.4022 - accuracy: 0.3866 - val_loss: 0.6707 - val_accuracy: 1.0000\n",
      "Epoch 25/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3986 - accuracy: 0.3529 - val_loss: 0.5739 - val_accuracy: 1.0000\n",
      "Epoch 26/200\n",
      "60/60 [==============================] - 4s 58ms/step - loss: 1.4054 - accuracy: 0.2857 - val_loss: 0.7987 - val_accuracy: 1.0000\n",
      "Epoch 27/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3570 - accuracy: 0.3866 - val_loss: 0.3533 - val_accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4122 - accuracy: 0.3529 - val_loss: 0.5445 - val_accuracy: 1.0000\n",
      "Epoch 29/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4110 - accuracy: 0.3782 - val_loss: 0.9420 - val_accuracy: 1.0000\n",
      "Epoch 30/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3854 - accuracy: 0.3109 - val_loss: 0.7783 - val_accuracy: 1.0000\n",
      "Epoch 31/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4118 - accuracy: 0.3529 - val_loss: 1.3123 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4205 - accuracy: 0.3361 - val_loss: 0.9333 - val_accuracy: 1.0000\n",
      "Epoch 33/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3918 - accuracy: 0.3697 - val_loss: 0.3434 - val_accuracy: 1.0000\n",
      "Epoch 34/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3853 - accuracy: 0.3866 - val_loss: 0.7570 - val_accuracy: 1.0000\n",
      "Epoch 35/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3896 - accuracy: 0.3697 - val_loss: 1.1284 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4065 - accuracy: 0.3950 - val_loss: 1.4796 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4066 - accuracy: 0.3277 - val_loss: 0.5182 - val_accuracy: 1.0000\n",
      "Epoch 38/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4133 - accuracy: 0.3782 - val_loss: 0.9325 - val_accuracy: 1.0000\n",
      "Epoch 39/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.4040 - accuracy: 0.3193 - val_loss: 1.0355 - val_accuracy: 1.0000\n",
      "Epoch 40/200\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 1.4197 - accuracy: 0.3361 - val_loss: 0.4532 - val_accuracy: 1.0000\n",
      "Epoch 41/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.4037 - accuracy: 0.3697 - val_loss: 1.0794 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 1.4230 - accuracy: 0.3782 - val_loss: 1.2707 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4017 - accuracy: 0.3782 - val_loss: 1.0566 - val_accuracy: 1.0000\n",
      "Epoch 44/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4367 - accuracy: 0.3782 - val_loss: 0.9080 - val_accuracy: 1.0000\n",
      "Epoch 45/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3943 - accuracy: 0.3613 - val_loss: 0.8911 - val_accuracy: 1.0000\n",
      "Epoch 46/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3690 - accuracy: 0.3529 - val_loss: 1.1033 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3939 - accuracy: 0.3782 - val_loss: 2.0067 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4347 - accuracy: 0.3361 - val_loss: 1.2503 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3900 - accuracy: 0.3361 - val_loss: 1.1516 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4216 - accuracy: 0.3529 - val_loss: 0.8978 - val_accuracy: 1.0000\n",
      "Epoch 51/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.4014 - accuracy: 0.3782 - val_loss: 0.2910 - val_accuracy: 1.0000\n",
      "Epoch 52/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4151 - accuracy: 0.3613 - val_loss: 0.5325 - val_accuracy: 1.0000\n",
      "Epoch 53/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4000 - accuracy: 0.3445 - val_loss: 0.7531 - val_accuracy: 1.0000\n",
      "Epoch 54/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3853 - accuracy: 0.3782 - val_loss: 0.7123 - val_accuracy: 1.0000\n",
      "Epoch 55/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3888 - accuracy: 0.3866 - val_loss: 0.9633 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3785 - accuracy: 0.3361 - val_loss: 1.0690 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3766 - accuracy: 0.3529 - val_loss: 1.2222 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3944 - accuracy: 0.3445 - val_loss: 1.2173 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.4025 - accuracy: 0.3613 - val_loss: 1.1505 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3828 - accuracy: 0.4034 - val_loss: 0.9132 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3818 - accuracy: 0.4118 - val_loss: 1.2455 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3706 - accuracy: 0.3529 - val_loss: 0.8717 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3548 - accuracy: 0.4118 - val_loss: 0.7499 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3480 - accuracy: 0.4202 - val_loss: 0.7981 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3421 - accuracy: 0.4118 - val_loss: 0.7851 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3483 - accuracy: 0.4202 - val_loss: 0.9014 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3459 - accuracy: 0.4202 - val_loss: 0.9139 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3457 - accuracy: 0.4202 - val_loss: 0.8778 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3414 - accuracy: 0.4202 - val_loss: 0.8999 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3356 - accuracy: 0.4202 - val_loss: 0.8409 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3353 - accuracy: 0.4202 - val_loss: 0.9136 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3342 - accuracy: 0.4202 - val_loss: 0.9071 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3372 - accuracy: 0.4202 - val_loss: 0.9186 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3282 - accuracy: 0.4202 - val_loss: 0.8296 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3319 - accuracy: 0.4202 - val_loss: 0.8430 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3284 - accuracy: 0.4202 - val_loss: 0.7982 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3342 - accuracy: 0.4202 - val_loss: 0.8772 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3307 - accuracy: 0.4202 - val_loss: 0.8168 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3328 - accuracy: 0.4202 - val_loss: 0.8270 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3286 - accuracy: 0.4202 - val_loss: 0.8620 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3273 - accuracy: 0.4202 - val_loss: 0.9091 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3234 - accuracy: 0.4202 - val_loss: 0.8584 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3259 - accuracy: 0.4202 - val_loss: 0.8146 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3266 - accuracy: 0.4202 - val_loss: 0.8510 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3251 - accuracy: 0.4202 - val_loss: 0.8586 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3228 - accuracy: 0.4202 - val_loss: 0.7925 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3253 - accuracy: 0.4202 - val_loss: 0.8384 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3289 - accuracy: 0.4202 - val_loss: 0.8613 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3250 - accuracy: 0.4202 - val_loss: 0.8293 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3215 - accuracy: 0.4202 - val_loss: 0.7957 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3332 - accuracy: 0.4202 - val_loss: 0.8333 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3260 - accuracy: 0.4202 - val_loss: 0.8157 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3285 - accuracy: 0.4202 - val_loss: 0.8348 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3306 - accuracy: 0.4202 - val_loss: 0.8488 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3329 - accuracy: 0.4202 - val_loss: 0.8074 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3280 - accuracy: 0.4202 - val_loss: 0.8393 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3295 - accuracy: 0.4202 - val_loss: 0.8489 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3277 - accuracy: 0.4202 - val_loss: 0.8683 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3239 - accuracy: 0.4202 - val_loss: 0.7751 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3341 - accuracy: 0.4202 - val_loss: 0.8465 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3288 - accuracy: 0.4202 - val_loss: 0.8703 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3338 - accuracy: 0.4202 - val_loss: 0.8648 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3248 - accuracy: 0.4202 - val_loss: 0.7875 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3281 - accuracy: 0.4202 - val_loss: 0.9074 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3252 - accuracy: 0.4202 - val_loss: 0.8511 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3281 - accuracy: 0.4202 - val_loss: 0.8578 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3256 - accuracy: 0.4202 - val_loss: 0.7637 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3291 - accuracy: 0.4202 - val_loss: 0.7472 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3339 - accuracy: 0.4202 - val_loss: 0.9183 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3249 - accuracy: 0.4202 - val_loss: 0.9034 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "60/60 [==============================] - 4s 58ms/step - loss: 1.3283 - accuracy: 0.4202 - val_loss: 0.8732 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 1.3207 - accuracy: 0.4202 - val_loss: 0.7244 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3323 - accuracy: 0.4202 - val_loss: 0.8411 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3330 - accuracy: 0.4202 - val_loss: 0.9241 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3267 - accuracy: 0.4202 - val_loss: 0.7932 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3294 - accuracy: 0.4202 - val_loss: 0.8372 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3278 - accuracy: 0.4202 - val_loss: 0.8196 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3311 - accuracy: 0.4202 - val_loss: 0.8187 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3323 - accuracy: 0.4202 - val_loss: 0.8924 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3294 - accuracy: 0.4202 - val_loss: 0.8519 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3250 - accuracy: 0.4202 - val_loss: 0.8558 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3242 - accuracy: 0.4202 - val_loss: 0.8696 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3322 - accuracy: 0.4202 - val_loss: 0.8991 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3260 - accuracy: 0.4202 - val_loss: 0.8915 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3266 - accuracy: 0.4202 - val_loss: 0.8570 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3265 - accuracy: 0.4202 - val_loss: 0.8544 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3272 - accuracy: 0.4202 - val_loss: 0.8650 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3257 - accuracy: 0.4202 - val_loss: 0.8687 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3232 - accuracy: 0.4202 - val_loss: 0.8138 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3274 - accuracy: 0.4202 - val_loss: 0.8723 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3216 - accuracy: 0.4202 - val_loss: 0.7900 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3240 - accuracy: 0.4202 - val_loss: 0.8473 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3245 - accuracy: 0.4202 - val_loss: 0.8808 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3238 - accuracy: 0.4202 - val_loss: 0.8093 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3282 - accuracy: 0.4202 - val_loss: 0.8279 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3246 - accuracy: 0.4202 - val_loss: 0.8500 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3236 - accuracy: 0.4202 - val_loss: 0.8466 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3244 - accuracy: 0.4202 - val_loss: 0.8325 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3216 - accuracy: 0.4202 - val_loss: 0.8334 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3259 - accuracy: 0.4202 - val_loss: 0.8584 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3236 - accuracy: 0.4202 - val_loss: 0.8465 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3243 - accuracy: 0.4202 - val_loss: 0.8561 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3243 - accuracy: 0.4202 - val_loss: 0.8192 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3260 - accuracy: 0.4202 - val_loss: 0.8437 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3256 - accuracy: 0.4202 - val_loss: 0.8293 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3252 - accuracy: 0.4202 - val_loss: 0.8413 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3240 - accuracy: 0.4202 - val_loss: 0.8387 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3274 - accuracy: 0.4202 - val_loss: 0.8402 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3255 - accuracy: 0.4202 - val_loss: 0.8593 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3243 - accuracy: 0.4202 - val_loss: 0.7987 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3246 - accuracy: 0.4202 - val_loss: 0.8280 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3251 - accuracy: 0.4202 - val_loss: 0.8281 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3234 - accuracy: 0.4202 - val_loss: 0.8781 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3261 - accuracy: 0.4202 - val_loss: 0.8845 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3261 - accuracy: 0.4202 - val_loss: 0.9041 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3262 - accuracy: 0.4202 - val_loss: 0.8432 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3229 - accuracy: 0.4202 - val_loss: 0.7856 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3233 - accuracy: 0.4202 - val_loss: 0.7846 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3256 - accuracy: 0.4202 - val_loss: 0.8230 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3268 - accuracy: 0.4202 - val_loss: 0.8624 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3244 - accuracy: 0.4202 - val_loss: 0.8564 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3228 - accuracy: 0.4202 - val_loss: 0.8245 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3260 - accuracy: 0.4202 - val_loss: 0.8646 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3228 - accuracy: 0.4202 - val_loss: 0.8739 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3243 - accuracy: 0.4202 - val_loss: 0.8561 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3244 - accuracy: 0.4202 - val_loss: 0.8166 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3244 - accuracy: 0.4202 - val_loss: 0.9031 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3237 - accuracy: 0.4202 - val_loss: 0.8094 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3250 - accuracy: 0.4202 - val_loss: 0.8105 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3258 - accuracy: 0.4202 - val_loss: 0.8428 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3258 - accuracy: 0.4202 - val_loss: 0.8451 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3240 - accuracy: 0.4202 - val_loss: 0.8810 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3251 - accuracy: 0.4202 - val_loss: 0.8483 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3240 - accuracy: 0.4202 - val_loss: 0.9013 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3221 - accuracy: 0.4202 - val_loss: 0.9039 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3229 - accuracy: 0.4202 - val_loss: 0.8239 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3209 - accuracy: 0.4202 - val_loss: 0.7849 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3260 - accuracy: 0.4202 - val_loss: 0.8797 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3240 - accuracy: 0.4202 - val_loss: 0.8690 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3245 - accuracy: 0.4202 - val_loss: 0.8645 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 1.3267 - accuracy: 0.4202 - val_loss: 0.8604 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3232 - accuracy: 0.4202 - val_loss: 0.8276 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3250 - accuracy: 0.4202 - val_loss: 0.8306 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3256 - accuracy: 0.4202 - val_loss: 0.8239 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3247 - accuracy: 0.4202 - val_loss: 0.8245 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3218 - accuracy: 0.4202 - val_loss: 0.8450 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3253 - accuracy: 0.4202 - val_loss: 0.8455 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3262 - accuracy: 0.4202 - val_loss: 0.8919 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "60/60 [==============================] - 4s 59ms/step - loss: 1.3247 - accuracy: 0.4202 - val_loss: 0.8933 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3229 - accuracy: 0.4202 - val_loss: 0.8235 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3263 - accuracy: 0.4202 - val_loss: 0.8493 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3231 - accuracy: 0.4202 - val_loss: 0.9195 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3258 - accuracy: 0.4202 - val_loss: 0.8831 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3247 - accuracy: 0.4202 - val_loss: 0.8352 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3245 - accuracy: 0.4202 - val_loss: 0.8097 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3241 - accuracy: 0.4202 - val_loss: 0.8049 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "60/60 [==============================] - 3s 57ms/step - loss: 1.3251 - accuracy: 0.4202 - val_loss: 0.8920 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3256 - accuracy: 0.4202 - val_loss: 0.8419 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3242 - accuracy: 0.4202 - val_loss: 0.8497 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "60/60 [==============================] - 3s 58ms/step - loss: 1.3244 - accuracy: 0.4202 - val_loss: 0.8993 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "opt='RMSProp'\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.20)\n",
    "history = model.fit(X_train, y_train, batch_size=2, epochs=200, verbose=1,validation_split=0.005, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a35c058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0  0]\n",
      " [ 5  0  0  0]\n",
      " [ 5  0  0  0]\n",
      " [ 8  0  0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      1.00      0.57        12\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         5\n",
      "           3       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.40        30\n",
      "   macro avg       0.10      0.25      0.14        30\n",
      "weighted avg       0.16      0.40      0.23        30\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ying\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "yhat_classes = model.predict_classes(X_test, verbose=0)\n",
    "y_test_original = y_test.argmax(1)\n",
    "y_train_original = y_train.argmax(1)\n",
    "labels = np.unique(y_test_original)\n",
    "a= confusion_matrix(y_test_original, yhat_classes)\n",
    "print(a)\n",
    "print(classification_report(y_test_original, yhat_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa26966d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  1  0]\n",
      " [ 3  1  1  0]\n",
      " [ 1  0  3  1]\n",
      " [ 3  2  1  2]]\n",
      "train score: 1.0\n",
      "test score: 0.5666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "svm_model = svm.SVC(kernel = 'linear', C = 2,decision_function_shape='ovo').fit(X_train,y_train_original)\n",
    "\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test_original, y_pred))\n",
    "\n",
    "print(\"train score:\",svm_model.score(X_train,y_train_original))\n",
    "print(\"test score:\",svm_model.score(X_test,y_test_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada640d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
